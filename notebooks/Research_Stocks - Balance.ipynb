{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew3690/F-A_root_project/blob/Brazil/C%C3%B3pia_de_Research_Stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4JRZip-LxGM"
      },
      "source": [
        "# Downloading Modules:\n",
        "Spark, pyspark, Java.\n",
        "\n",
        "Bellow it is the old fashion way, risky not Recomended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "g7uf9T1SAwMe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' \\n# # Installing Java\\n! apt-get install openjdk-8-jdk-headless -qq > /dev/null\\n# # Dowload Spark\\n! wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\\n# # Decompressing archives\\n! tar xf spark-3.2.1-bin-hadoop2.7.tgz\\n# # installing findspark\\n! pip install -q findspark\\n# # installing pyspark\\n! pip install pyspark==3.2.1\\n '"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" \n",
        "# # Installing Java\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# # Dowload Spark\n",
        "! wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
        "# # Decompressing archives\n",
        "! tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
        "# # installing findspark\n",
        "! pip install -q findspark\n",
        "# # installing pyspark\n",
        "! pip install pyspark==3.2.1\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "V3ZS9Z2vYrxT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' \\n# Importing os library\\nimport os\\n# # Java envirorment variable\\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\\n# # Spark envirorment variable\\nos.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\\n '"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" \n",
        "# Importing os library\n",
        "import os\n",
        "# # Java envirorment variable\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# # Spark envirorment variable\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTYBnobCPITD"
      },
      "source": [
        "# Better and consistent library that makes the same function as the code above\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boHa2yWHE2TA",
        "outputId": "2dd293d0-7923-4351-a6b7-66b27aea85f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\video\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.1)\n",
            "Requirement already satisfied: py4j in c:\\users\\video\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.9.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyodbc in c:\\users\\video\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.0.35)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark py4j\n",
        "! pip install pyodbc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0lpamJ2PhzT"
      },
      "source": [
        "**Importing modules and pandas library that will be used later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "oLpozDIlCsnf"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark\n",
        "import pandas as pd\n",
        "import pyodbc\n",
        "# import findspark\n",
        "\n",
        "# findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "rLgNaJpJZWQf",
        "outputId": "375d6ea4-ab28-428e-9c70-d6742f2396f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://DESKTOP-7VLQ9AP:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x220d5eac810>"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# instatianting spark instance\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gooogle Colab Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70iuSZT29Tff",
        "outputId": "7fa9d57b-f0c2-4c24-d1d3-841ff740eb4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" \\nfrom google.colab import drive\\ndrive.mount('/content/gdrive', force_remount=True) \\n\""
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEDLrMlgMaTM"
      },
      "source": [
        "# Next cells acquire parquet data from remote files, and transpose it to spark format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "pFHrGmPvaSTT"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/RAW_DATA/Parquet/BrStocksFormated.parquet\"\n",
        "\n",
        "stocks = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "6zQPXfDcMtB5"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/RAW_DATA/Parquet/Ebit.parquet\"\n",
        "\n",
        "ebit = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "8ZQgZzJ3NCB6"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/RAW_DATA/Parquet/Stat.parquet\"\n",
        "\n",
        "stat = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "66vvcNGCCZoN"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/RAW_DATA/Parquet/Price.parquet\"\n",
        "\n",
        "price = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "fille =r'C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/RAW_DATA/Parquet/Balance.parquet'\n",
        "\n",
        "balance = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SubWtlFnNJHn"
      },
      "source": [
        "Creating Tables in order to manipulate data in SQL format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "UD38ZEtovRHd"
      },
      "outputs": [],
      "source": [
        "# Stocks table\n",
        "stocks.createOrReplaceTempView(\"General\")\n",
        "# Ebit table\n",
        "ebit.createOrReplaceTempView(\"Ebit\")\n",
        "# Stat table\n",
        "stat.createOrReplaceTempView(\"Stat\")\n",
        "# Price table\n",
        "price.createOrReplaceTempView(\"Price\")\n",
        "# Balance table\n",
        "balance.createOrReplaceTempView(\"Balance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv8S8_6bCqBk"
      },
      "source": [
        "# Note 1: \n",
        "'DetToEquity' must be in percentage, try to get it done here or otherwise in Power Bi\n",
        "\n",
        "---\n",
        "\n",
        "# Note 2: \n",
        "Find a way to calculate Beta values from \n",
        "historical data get it from other sources, but try to calculate it localy (Talk with Felipe, about the period of time that will be used as 'ytd' or montlhy). \n",
        "\n",
        "# Fixed:\n",
        "Beta values could be acquired trough yahoo finance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKpxqfnyBnmn"
      },
      "source": [
        "Listing brazilian companies that will be researched and getting hystorical financial data\n",
        "filters that our Analyst indicates: Raking companies by: EBIT/EV > 0, ROE > 0, **Daily equity < 1.000.000.000**, revenueGrowth > 0 AND Will be done apart :(5-year-history) and all margins must be postive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "_KbqxMcV6ACp"
      },
      "outputs": [],
      "source": [
        "# Already called at Calc Table\n",
        "Gen = spark.sql(\"\"\"\n",
        "SELECT * FROM General\n",
        "WHERE Moeda != 'USD' AND EBITDA != 0 AND ROA != 0 AND ROE != 0;\n",
        "\"\"\").createOrReplaceTempView(\"Gen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "lf6g77UP6T4R"
      },
      "outputs": [],
      "source": [
        "#Gen.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "FjPkiCwx8xeo"
      },
      "outputs": [],
      "source": [
        "# Already called at RSCH table\n",
        "Ebit = spark.sql(\"\"\"\n",
        "SELECT * FROM Ebit\n",
        "where Divida_Liquida != 0;\n",
        "\"\"\").createOrReplaceTempView(\"Debt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "UBBFDO-Z89_w"
      },
      "outputs": [],
      "source": [
        "#Ebit.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "RapgMFkNEhWt"
      },
      "outputs": [],
      "source": [
        "# Already called at RSCH table\n",
        "Price = spark.sql(\"\"\"\n",
        "SELECT * FROM Price\n",
        "WHERE valor_de_mercado != 0;\n",
        "\"\"\")#.createOrReplaceTempView(\"Prices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "u3wQByiGE9qO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------------+-----------------+-----------------+\n",
            "|  Ticker|valor_de_mercado|volume_de_mercado|__index_level_0__|\n",
            "+--------+----------------+-----------------+-----------------+\n",
            "|ZAMP3.SA|      1290876288|                0|                0|\n",
            "|AERI3.SA|       964650304|                0|                3|\n",
            "|DOTZ3.SA|       113162640|                0|                5|\n",
            "|MLAS3.SA|      1763443968|                0|                8|\n",
            "|NINJ3.SA|       134109408|                0|               11|\n",
            "|MODL3.SA|      1179109888|                0|               14|\n",
            "|VITT3.SA|      1594519040|                0|               15|\n",
            "|KRSA3.SA|       874195328|                0|               16|\n",
            "|ALLD3.SA|       470764032|                0|               23|\n",
            "|ATMP3.SA|        27776526|                0|               25|\n",
            "|JSLG3.SA|      1982957056|                0|               27|\n",
            "|ELMD3.SA|      1802294016|                0|               29|\n",
            "|OPCT3.SA|       617591488|                0|               31|\n",
            "|WEST3.SA|       113666680|                0|               32|\n",
            "|CSED3.SA|      1016417792|                0|               33|\n",
            "|BMOB3.SA|      1232547456|                0|               34|\n",
            "|MBLY3.SA|       340768000|                0|               36|\n",
            "|ESPA3.SA|       433707616|                0|               37|\n",
            "|NGRD3.SA|       274267648|                0|               40|\n",
            "|AVLL3.SA|       219868096|                0|               41|\n",
            "+--------+----------------+-----------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Price.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abGJeNp68atZ"
      },
      "source": [
        "Alternative operations, while dealing with a little amount of data, and it can be joined here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "qa3_DcgM9cFg"
      },
      "outputs": [],
      "source": [
        "Stat = spark.sql(\"\"\"\n",
        "SELECT * FROM Stat\n",
        "WHERE Beta != 0.5;\n",
        "\"\"\")#.createOrReplaceTempView(\"Stat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Stat.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "_EHHjN73m9Zk"
      },
      "outputs": [],
      "source": [
        "CALCULATE = spark.sql(\"\"\"\n",
        "SELECT * FROM Gen\n",
        "WHERE Margem_Bruta > 0.0 AND Margem_EBITIDA > 0.0 AND \n",
        "Margem_Operacional > 0.0 AND Margem_liquida > 0.0 AND \n",
        "ROE > 0 AND Crescimento_de_Receita_3T > 0;\n",
        "\"\"\")#.createOrReplaceTempView(\"Calc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLS_f98nmjji",
        "outputId": "48485c91-f0eb-4f67-a848-4b06613ed014"
      },
      "outputs": [],
      "source": [
        "#CALCULATE.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "uGV8lO4pNWcT"
      },
      "outputs": [],
      "source": [
        "RSCH = spark.sql(\"\"\"\n",
        "SELECT p.Ticker, \n",
        "       p.valor_de_mercado, \n",
        "       p.volume_de_mercado, \n",
        "       e.EBIT, \n",
        "       e.Divida_Liquida \n",
        "FROM Price as p, Ebit as e\n",
        "WHERE (p.valor_de_mercado + e.Divida_Liquida)/e.EBIT > 0.0 AND \n",
        "p.Ticker == e.Ticker; \n",
        "\"\"\")#.createOrReplaceTempView(\"RSCH\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "Balance = spark.sql(\"\"\"\n",
        "SELECT  Ticker,\n",
        "        Data_de_Reporte,\n",
        "        Moeda,\n",
        "        Receita_a_Pagar,\n",
        "        Receitas_a_Receber,\n",
        "        Bens_de_Capital\n",
        "FROM Balance\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------------------+-----+---------------+------------------+---------------+\n",
            "|   Ticker|    Data_de_Reporte|Moeda|Receita_a_Pagar|Receitas_a_Receber|Bens_de_Capital|\n",
            "+---------+-------------------+-----+---------------+------------------+---------------+\n",
            "|A2MC34.SA|2019-12-30 21:00:00|  USD|        5.433E8|           1.603E8|      1000000.0|\n",
            "|A2MC34.SA|2020-12-30 21:00:00|  USD|        2.988E8|            2.31E7|      2300000.0|\n",
            "|A2MC34.SA|2021-12-30 21:00:00|  USD|        3.771E8|            8.54E7|      5100000.0|\n",
            "| AALR3.SA|2019-12-30 21:00:00|  BRL|        5.667E7|          8.8789E7|      6.12412E8|\n",
            "| AALR3.SA|2020-12-30 21:00:00|  BRL|       9.4887E7|          7.9679E7|      6.12412E8|\n",
            "| AALR3.SA|2021-12-30 21:00:00|  BRL|      1.17548E8|         1.04502E8|      6.12412E8|\n",
            "|AAPL34.SA|2019-09-29 21:00:00|  USD|      4.6236E10|         2.2926E10|      4.5174E10|\n",
            "|AAPL34.SA|2020-09-29 21:00:00|  USD|      4.2296E10|          1.612E10|      5.0779E10|\n",
            "|AAPL34.SA|2021-09-29 21:00:00|  USD|      5.4763E10|         2.6278E10|      5.7365E10|\n",
            "|AAPL34.SA|2022-09-29 21:00:00|  USD|      6.4115E10|         2.8184E10|      6.4849E10|\n",
            "|ABTT34.SA|2019-12-30 21:00:00|  USD|        3.252E9|           5.425E9|      2.3853E10|\n",
            "|ABTT34.SA|2020-12-30 21:00:00|  USD|        3.946E9|           6.414E9|      2.4145E10|\n",
            "|ABTT34.SA|2021-12-30 21:00:00|  USD|        4.408E9|           6.487E9|       2.447E10|\n",
            "|ABTT34.SA|2022-12-30 21:00:00|  USD|        4.607E9|           6.218E9|      2.4709E10|\n",
            "| AERI3.SA|2019-12-30 21:00:00|  BRL|      1.16629E8|          9.8532E7|       3.6183E7|\n",
            "| AERI3.SA|2020-12-30 21:00:00|  BRL|      2.05304E8|         2.20132E8|      8.16047E8|\n",
            "| AERI3.SA|2021-12-30 21:00:00|  BRL|      4.45286E8|         1.26877E8|      8.15102E8|\n",
            "| AERI3.SA|2022-12-30 21:00:00|  BRL|      3.36048E8|               0.0|      8.15102E8|\n",
            "| AESB3.SA|2019-12-30 21:00:00|  BRL|           null|              null|            0.0|\n",
            "| AESB3.SA|2020-12-30 21:00:00|  BRL|           null|              null|          500.0|\n",
            "+---------+-------------------+-----+---------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Balance.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "calendario = spark.sql(\"\"\"\n",
        "SELECT \n",
        "    CAST(Data_de_Reporte) AS MIN_DATE\n",
        "FROM Balance \n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+\n",
            "|           MIN_DATE|           MAX_DATE|\n",
            "+-------------------+-------------------+\n",
            "|2019-03-30 21:00:00|2023-01-30 21:00:00|\n",
            "+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "calendario.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGP5as1CK1uo"
      },
      "source": [
        "ev = número total de papeis x cotação + divida liquida\n",
        "ev = market value +  liquid debt \n",
        "\n",
        "PSR = PREÇO DA AÇÃO / RECEITA LIQUIDA POR AÇÃO "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MJkJf8SguRE"
      },
      "source": [
        "Pandas setting DataFrame to pandas format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "-FFxq6uLe49F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\video\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "  series = series.astype(t, copy=False)\n",
            "c:\\Users\\video\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "  series = series.astype(t, copy=False)\n",
            "c:\\Users\\video\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "  series = series.astype(t, copy=False)\n"
          ]
        }
      ],
      "source": [
        "df_stat = Stat.toPandas()\n",
        "\n",
        "df_calc = CALCULATE.toPandas()\n",
        "\n",
        "df_rsc = RSCH.toPandas()\n",
        "\n",
        "df_balance = Balance.toPandas()\n",
        "\n",
        "df_calendario = calendario.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Data_de_Reporte</th>\n",
              "      <th>Moeda</th>\n",
              "      <th>Receita_a_Pagar</th>\n",
              "      <th>Receitas_a_Receber</th>\n",
              "      <th>Bens_de_Capital</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A2MC34.SA</td>\n",
              "      <td>2019-12-30 21:00:00</td>\n",
              "      <td>USD</td>\n",
              "      <td>543300000.0</td>\n",
              "      <td>160300000.0</td>\n",
              "      <td>1.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A2MC34.SA</td>\n",
              "      <td>2020-12-30 21:00:00</td>\n",
              "      <td>USD</td>\n",
              "      <td>298800000.0</td>\n",
              "      <td>23100000.0</td>\n",
              "      <td>2.300000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2MC34.SA</td>\n",
              "      <td>2021-12-30 21:00:00</td>\n",
              "      <td>USD</td>\n",
              "      <td>377100000.0</td>\n",
              "      <td>85400000.0</td>\n",
              "      <td>5.100000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AALR3.SA</td>\n",
              "      <td>2019-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>56670000.0</td>\n",
              "      <td>88789000.0</td>\n",
              "      <td>6.124120e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AALR3.SA</td>\n",
              "      <td>2020-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>94887000.0</td>\n",
              "      <td>79679000.0</td>\n",
              "      <td>6.124120e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>YDUQ3.SA</td>\n",
              "      <td>2020-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>251229000.0</td>\n",
              "      <td>890151000.0</td>\n",
              "      <td>1.139887e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>YDUQ3.SA</td>\n",
              "      <td>2021-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>183529000.0</td>\n",
              "      <td>957746000.0</td>\n",
              "      <td>1.139887e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>ZAMP3.SA</td>\n",
              "      <td>2019-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>286432000.0</td>\n",
              "      <td>60361000.0</td>\n",
              "      <td>9.507680e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>ZAMP3.SA</td>\n",
              "      <td>2020-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>217616000.0</td>\n",
              "      <td>105011000.0</td>\n",
              "      <td>1.461068e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>ZAMP3.SA</td>\n",
              "      <td>2021-12-30 21:00:00</td>\n",
              "      <td>BRL</td>\n",
              "      <td>247917000.0</td>\n",
              "      <td>139267000.0</td>\n",
              "      <td>1.461068e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Ticker     Data_de_Reporte Moeda  Receita_a_Pagar  \\\n",
              "0     A2MC34.SA 2019-12-30 21:00:00   USD      543300000.0   \n",
              "1     A2MC34.SA 2020-12-30 21:00:00   USD      298800000.0   \n",
              "2     A2MC34.SA 2021-12-30 21:00:00   USD      377100000.0   \n",
              "3      AALR3.SA 2019-12-30 21:00:00   BRL       56670000.0   \n",
              "4      AALR3.SA 2020-12-30 21:00:00   BRL       94887000.0   \n",
              "...         ...                 ...   ...              ...   \n",
              "1025   YDUQ3.SA 2020-12-30 21:00:00   BRL      251229000.0   \n",
              "1026   YDUQ3.SA 2021-12-30 21:00:00   BRL      183529000.0   \n",
              "1027   ZAMP3.SA 2019-12-30 21:00:00   BRL      286432000.0   \n",
              "1028   ZAMP3.SA 2020-12-30 21:00:00   BRL      217616000.0   \n",
              "1029   ZAMP3.SA 2021-12-30 21:00:00   BRL      247917000.0   \n",
              "\n",
              "      Receitas_a_Receber  Bens_de_Capital  \n",
              "0            160300000.0     1.000000e+06  \n",
              "1             23100000.0     2.300000e+06  \n",
              "2             85400000.0     5.100000e+06  \n",
              "3             88789000.0     6.124120e+08  \n",
              "4             79679000.0     6.124120e+08  \n",
              "...                  ...              ...  \n",
              "1025         890151000.0     1.139887e+09  \n",
              "1026         957746000.0     1.139887e+09  \n",
              "1027          60361000.0     9.507680e+08  \n",
              "1028         105011000.0     1.461068e+09  \n",
              "1029         139267000.0     1.461068e+09  \n",
              "\n",
              "[1030 rows x 6 columns]"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_balance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Excel format tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "BNc_zBG8j3zL"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "df_stat.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Excel/Stat.xlsx\",\n",
        "                 sheet_name=\"stat\")\n",
        "\n",
        "df_calc.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Calcl.xlsx\",\n",
        "                 sheet_name=\"calc\")\n",
        "\n",
        "df_rsc.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/RSCH.xlsx\",\n",
        "                sheet_name=\"research\")\n",
        "\n",
        "df_balance.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Balance.xlsx\",\n",
        "                sheet_name=\"balance\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_balance.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Balance.parquet\")\n",
        "\n",
        "df_stat.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Calcl.parquet\")\n",
        "\n",
        "df_rsc.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/RSCH.parquet\")\n",
        "\n",
        "df_calc.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Calcl.parquet\")\n",
        "\n",
        "df_calendario.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Calendario.parquet\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Local Connection to SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = pyodbc.connect('Driver={SQL Server};'\n",
        "                      'Server=DESKTOP-7VLQ9AP\\SQLEXPRESS;'\n",
        "                      'Database=FeA;'\n",
        "                      'Trusted_Connection=yes;'\n",
        "                      )\n",
        "\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Index([MIN_DATE, MAX_DATE], dtype=object)'"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(df_calendario.columns).replace(\"'\",\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "ename": "ProgrammingError",
          "evalue": "('42S22', \"[42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Nome de coluna 'index, MIN_DATE, MAX_DATE' inválido. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Existem menos colunas na instrução INSERT do que valores especificados na cláusula VALUES. O número de valores na cláusula VALUES deve corresponder ao número de colunas especificado na instrução INSERT. (110); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Não foi possível preparar uma ou mais instruções. (8180)\")",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[212], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m index, linha \u001b[39min\u001b[39;00m df_calendario\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> 2\u001b[0m         cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39m\"\u001b[39;49m\u001b[39mInsert into Balance ([index, MIN_DATE, MAX_DATE]) values(?,?)\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m                        linha\u001b[39m.\u001b[39;49mMIN_DATE, linha\u001b[39m.\u001b[39;49mMAX_DATE)\n\u001b[0;32m      4\u001b[0m cursor\u001b[39m.\u001b[39mcommit()\n",
            "\u001b[1;31mProgrammingError\u001b[0m: ('42S22', \"[42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Nome de coluna 'index, MIN_DATE, MAX_DATE' inválido. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Existem menos colunas na instrução INSERT do que valores especificados na cláusula VALUES. O número de valores na cláusula VALUES deve corresponder ao número de colunas especificado na instrução INSERT. (110); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Não foi possível preparar uma ou mais instruções. (8180)\")"
          ]
        }
      ],
      "source": [
        "for index, linha in df_calendario.iterrows():\n",
        "        cursor.execute(\"Insert into Balance ([MIN_DATE]) values(?)\",\n",
        "                       linha.MIN_DATE)\n",
        "cursor.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 MIN_DATE   2019-03-30 21:00:00\n",
            "MAX_DATE   2023-01-30 21:00:00\n",
            "Name: 0, dtype: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "for index, linha in df_calendario.iterrows():\n",
        "    print(index,linha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cloud Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'write'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[137], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m password \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mand010500\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# Please specify password here\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m   df_balance\u001b[39m.\u001b[39;49mwrite \\\n\u001b[0;32m     11\u001b[0m     \u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mcom.microsoft.sqlserver.jdbc.spark\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[0;32m     12\u001b[0m     \u001b[39m.\u001b[39mmode(\u001b[39m\"\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[0;32m     13\u001b[0m     \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m, url) \\\n\u001b[0;32m     14\u001b[0m     \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mdbtable\u001b[39m\u001b[39m\"\u001b[39m, table_name) \\\n\u001b[0;32m     15\u001b[0m     \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, username) \\\n\u001b[0;32m     16\u001b[0m     \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m\"\u001b[39m, password) \\\n\u001b[0;32m     17\u001b[0m     \u001b[39m.\u001b[39msave()\n\u001b[0;32m     19\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m error :\n\u001b[0;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConnector write failed\u001b[39m\u001b[39m\"\u001b[39m, error)\n",
            "File \u001b[1;32mc:\\Users\\video\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'write'"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "server_name = \"jdbc:sqlserver://DESKTOP-7VLQ9AP\\SQLEXPRESS\"\n",
        "database_name = \"FeA\"\n",
        "url = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n",
        "\n",
        "table_name = \"Balance\"\n",
        "username = \"SQL_ADM\"\n",
        "password = \"and010500\" # Please specify password here\n",
        "\n",
        "try:\n",
        "  df_balance.write \\\n",
        "    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", table_name) \\\n",
        "    .option(\"user\", username) \\\n",
        "    .option(\"password\", password) \\\n",
        "    .save()\n",
        "\n",
        "except ValueError as error :\n",
        "    print(\"Connector write failed\", error)\n",
        " \"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "598092329803f2218a82426b846daf764474eee9678032408d5a767cd4823601"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
