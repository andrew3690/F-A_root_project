{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew3690/F-A_root_project/blob/Brazil/C%C3%B3pia_de_Research_Stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4JRZip-LxGM"
      },
      "source": [
        "# Downloading Modules:\n",
        "Spark, pyspark, Java.\n",
        "\n",
        "Bellow it is the old fashion way, risky not Recomended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7uf9T1SAwMe"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "# # Installing Java\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# # Dowload Spark\n",
        "! wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
        "# # Decompressing archives\n",
        "! tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
        "# # installing findspark\n",
        "! pip install -q findspark\n",
        "# # installing pyspark\n",
        "! pip install pyspark==3.2.1\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3ZS9Z2vYrxT"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "# Importing os library\n",
        "import os\n",
        "# # Java envirorment variable\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# # Spark envirorment variable\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTYBnobCPITD"
      },
      "source": [
        "# Better and consistent library that makes the same function as the code above\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boHa2yWHE2TA",
        "outputId": "2dd293d0-7923-4351-a6b7-66b27aea85f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\video\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.1)\n",
            "Requirement already satisfied: py4j in c:\\users\\video\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.9.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0lpamJ2PhzT"
      },
      "source": [
        "**Importing modules and pandas library that will be used later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oLpozDIlCsnf"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark\n",
        "import pandas as pd\n",
        "# import findspark\n",
        "\n",
        "# findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "rLgNaJpJZWQf",
        "outputId": "375d6ea4-ab28-428e-9c70-d6742f2396f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://DESKTOP-7VLQ9AP:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x1d8aa977050>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# instatianting spark instance\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gooogle Colab Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70iuSZT29Tff",
        "outputId": "7fa9d57b-f0c2-4c24-d1d3-841ff740eb4c"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEDLrMlgMaTM"
      },
      "source": [
        "# Next cells acquire parquet data from remote files, and transpose it to spark format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pFHrGmPvaSTT"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\RAW_DATA\\Parquet\\BrStocksFormated.parquet\"\n",
        "\n",
        "stocks = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6zQPXfDcMtB5"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\RAW_DATA\\Parquet\\Ebit.parquet\"\n",
        "\n",
        "ebit = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8ZQgZzJ3NCB6"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\RAW_DATA\\Parquet\\Stat.parquet\"\n",
        "\n",
        "stat = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "66vvcNGCCZoN"
      },
      "outputs": [],
      "source": [
        "fille = r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\RAW_DATA\\Parquet\\Price.parquet\"\n",
        "\n",
        "price = spark\\\n",
        "        .read.format(\"parquet\")\\\n",
        "        .option(\"inferSchema\", \"True\")\\\n",
        "        .option(\"header\",\"True\")\\\n",
        "        .parquet(fille)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SubWtlFnNJHn"
      },
      "source": [
        "Creating Tables in order to manipulate data in SQL format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UD38ZEtovRHd"
      },
      "outputs": [],
      "source": [
        "# Stocks table\n",
        "stocks.createOrReplaceTempView(\"General\")\n",
        "# Ebit table\n",
        "ebit.createOrReplaceTempView(\"Ebit\")\n",
        "# Stat table\n",
        "stat.createOrReplaceTempView(\"Stat\")\n",
        "# Price table\n",
        "price.createOrReplaceTempView(\"Price\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv8S8_6bCqBk"
      },
      "source": [
        "# Note 1: \n",
        "'DetToEquity' must be in percentage, try to get it done here or otherwise in Power Bi\n",
        "\n",
        "---\n",
        "\n",
        "# Note 2: \n",
        "Find a way to calculate Beta values from \n",
        "historical data get it from other sources, but try to calculate it localy (Talk with Felipe, about the period of time that will be used as 'ytd' or montlhy). \n",
        "\n",
        "# Fixed:\n",
        "Beta values could be acquired trough yahoo finance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKpxqfnyBnmn"
      },
      "source": [
        "Listing brazilian companies that will be researched and getting hystorical financial data\n",
        "filters that our Analyst indicates: Raking companies by: EBIT/EV > 0, ROE > 0, **Daily equity < 1.000.000.000**, revenueGrowth > 0 AND Will be done apart :(5-year-history) and all margins must be postive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_KbqxMcV6ACp"
      },
      "outputs": [],
      "source": [
        "# Already called at Calc Table\n",
        "Gen = spark.sql(\"\"\"\n",
        "SELECT * FROM General\n",
        "WHERE Moeda != 'USD' AND EBITDA != 0 AND ROA != 0 AND ROE != 0;\n",
        "\"\"\").createOrReplaceTempView(\"Gen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf6g77UP6T4R"
      },
      "outputs": [],
      "source": [
        "# Gen.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FjPkiCwx8xeo"
      },
      "outputs": [],
      "source": [
        "# Already called at RSCH table\n",
        "Ebit = spark.sql(\"\"\"\n",
        "SELECT * FROM Ebit\n",
        "where Divida_Liquida != 0;\n",
        "\"\"\").createOrReplaceTempView(\"Debt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UBBFDO-Z89_w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------------+\n",
            "|   Ticker|      EBIT|Divida_Liquida|\n",
            "+---------+----------+--------------+\n",
            "|A2MC34.SA|   1.692E8|      4.4884E9|\n",
            "|A2MC34.SA| -4.1726E9|      5.4075E9|\n",
            "|A2MC34.SA|  -8.219E8|      3.8355E9|\n",
            "| AALR3.SA| 1.27246E8|     5.26468E8|\n",
            "| AALR3.SA| -1.7508E7|     5.64752E8|\n",
            "| AALR3.SA|  8.6776E7|     6.50676E8|\n",
            "|AAPL34.SA| 6.9313E10|     5.9203E10|\n",
            "|AAPL34.SA| 6.9964E10|      7.442E10|\n",
            "|AAPL34.SA|1.11852E11|     8.9779E10|\n",
            "|AAPL34.SA|1.22034E11|     9.6423E10|\n",
            "|ABTT34.SA|   4.747E9|     1.4279E10|\n",
            "|ABTT34.SA|   5.514E9|     1.1909E10|\n",
            "|ABTT34.SA|   8.744E9|       8.251E9|\n",
            "| AERI3.SA| 1.44614E8|     3.10775E8|\n",
            "| AERI3.SA| 1.88977E8|     4.58448E8|\n",
            "| AERI3.SA| 1.83366E8|     5.65811E8|\n",
            "| AESB3.SA|-2.18234E8|    5.559478E9|\n",
            "| AGRO3.SA| 2.17969E8|     1.79226E8|\n",
            "| AGRO3.SA| 1.58777E8|     3.43068E8|\n",
            "| AGRO3.SA| 7.05361E8|      1.7548E7|\n",
            "+---------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Ebit.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RapgMFkNEhWt"
      },
      "outputs": [],
      "source": [
        "# Already called at RSCH table\n",
        "Price = spark.sql(\"\"\"\n",
        "SELECT * FROM Price\n",
        "WHERE valor_de_mercado != 0;\n",
        "\"\"\").createOrReplaceTempView(\"Prices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3wQByiGE9qO"
      },
      "outputs": [],
      "source": [
        "# Price.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abGJeNp68atZ"
      },
      "source": [
        "Alternative operations, while dealing with a little amount of data, and it can be joined here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qa3_DcgM9cFg"
      },
      "outputs": [],
      "source": [
        "Stat = spark.sql(\"\"\"\n",
        "SELECT * FROM Stat\n",
        "WHERE Beta != 0.5;\n",
        "\"\"\")#.createOrReplaceTempView(\"Stat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_EHHjN73m9Zk"
      },
      "outputs": [],
      "source": [
        "CALCULATE = spark.sql(\"\"\"\n",
        "SELECT * FROM Gen\n",
        "WHERE Margem_Bruta > 0.0 AND Margem_EBITIDA > 0.0 AND \n",
        "Margem_Operacional > 0.0 AND Margem_liquida > 0.0 AND \n",
        "ROE > 0 AND Crescimento_de_Receita_3T > 0;\n",
        "\"\"\")#.createOrReplaceTempView(\"Calc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLS_f98nmjji",
        "outputId": "48485c91-f0eb-4f67-a848-4b06613ed014"
      },
      "outputs": [],
      "source": [
        "#CALCULATE.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uGV8lO4pNWcT"
      },
      "outputs": [],
      "source": [
        "RSCH = spark.sql(\"\"\"\n",
        "SELECT p.Ticker, p.valor_de_mercado, p.volume_de_mercado, e.EBIT, e.Divida_Liquida FROM Price as p, Ebit as e\n",
        "WHERE (p.valor_de_mercado + e.Divida_Liquida)/e.EBIT > 0.0 AND \n",
        "p.Ticker == e.Ticker; \n",
        "\"\"\")#.createOrReplaceTempView(\"RSCH\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQb5boETie0X"
      },
      "outputs": [],
      "source": [
        "# DFT = spark.sql(\"\"\"\n",
        "# SELECT e.Ticker,\n",
        "#        Preco_Atual,\n",
        "#        Fluxo_de_caixa_total,\n",
        "#        Fluxo_de_caixa_por_acao,\n",
        "#        EBITDA,\n",
        "#        Divida_total,\n",
        "#        Liquidez_imediata,\n",
        "#        Liquidez_corrente,\n",
        "#        Receita_total,\n",
        "#        Divida_Patrimonio,\n",
        "#        Receita_por_acao,\n",
        "#        ROA,\n",
        "#        ROE,\n",
        "#        Lucro_Bruto,\n",
        "#        Fluxo_de_Caixa_Livre,\n",
        "#        Fluxo_de_caixa_operacional,\n",
        "#        Crescimento_de_Receita_3T,\n",
        "#        Margem_Bruta,\n",
        "#        Margem_EBITIDA,\n",
        "#        Margem_Operacional,\n",
        "#        Margem_liquida,\n",
        "#        Moeda,\n",
        "#        Crescimento_dos_ganhos_3T,\n",
        "#        EBIT,\n",
        "#        Divida_Liquida\n",
        "# FROM General g\n",
        "# LEFT JOIN Ebit e ON g.Ticker = e.Ticker\n",
        "# \"\"\").createOrReplaceTempView(\"Filtered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9cs56ygQ8fc"
      },
      "outputs": [],
      "source": [
        "# Stat = spark.sql(\"\"\"\n",
        "# SELECT f.Ticker,\n",
        "#        Preco_Atual,\n",
        "#        Fluxo_de_caixa_total,\n",
        "#        Fluxo_de_caixa_por_acao,\n",
        "#        EBITDA,\n",
        "#        Divida_total,\n",
        "#        Liquidez_imediata,\n",
        "#        Liquidez_corrente,\n",
        "#        Receita_total,\n",
        "#        Divida_Patrimonio,\n",
        "#        Receita_por_acao,\n",
        "#        ROA,\n",
        "#        ROE,\n",
        "#        Lucro_Bruto,\n",
        "#        Fluxo_de_Caixa_Livre,\n",
        "#        Fluxo_de_caixa_operacional,\n",
        "#        Crescimento_de_Receita_3T,\n",
        "#        Margem_Bruta,\n",
        "#        Margem_EBITIDA,\n",
        "#        Margem_Operacional,\n",
        "#        Margem_liquida,\n",
        "#        Moeda,\n",
        "#        Crescimento_dos_ganhos_3T,\n",
        "#        EBIT,\n",
        "#        Divida_Liquida,\n",
        "#       Beta,\n",
        "#       Margem_de_Lucro,\n",
        "#       Crescimento_de_receitas_4T,\n",
        "#       Valor_do_ultimo_dividendo\n",
        "# FROM Filtered f\n",
        "# LEFT JOIN Stat s ON f.Ticker = s.Ticker;\n",
        "# \"\"\").createOrReplaceTempView(\"Prstocks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV26cS4ZCuWq"
      },
      "outputs": [],
      "source": [
        "# DF = spark.sql(\"\"\"\n",
        "# SELECT a.Ticker,\n",
        "#        Preco_Atual,\n",
        "#        Fluxo_de_caixa_total,\n",
        "#        Fluxo_de_caixa_por_acao,\n",
        "#        EBITDA,\n",
        "#        Divida_total,\n",
        "#        Liquidez_imediata,\n",
        "#        Liquidez_corrente,\n",
        "#        Receita_total,\n",
        "#        Divida_Patrimonio,\n",
        "#        Receita_por_acao,\n",
        "#        ROA,\n",
        "#        ROE,\n",
        "#        Lucro_Bruto,\n",
        "#        Fluxo_de_Caixa_Livre,\n",
        "#        Fluxo_de_caixa_operacional,\n",
        "#        Crescimento_de_Receita_3T,\n",
        "#        Margem_Bruta,\n",
        "#        Margem_EBITIDA,\n",
        "#        Margem_Operacional,\n",
        "#        Margem_liquida,\n",
        "#        Moeda,\n",
        "#        Crescimento_dos_ganhos_3T,\n",
        "#        EBIT,\n",
        "#        Divida_Liquida,\n",
        "#        Beta,\n",
        "#        Margem_de_Lucro,\n",
        "#        Crescimento_de_receitas_4T,\n",
        "#        Valor_do_ultimo_dividendo,\n",
        "#        valor_de_mercado\n",
        "# FROM Prstocks a\n",
        "# LEFT JOIN Price p ON a.Ticker = p.Ticker;\n",
        "# \"\"\").createOrReplaceTempView('Stocks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGP5as1CK1uo"
      },
      "source": [
        "ev = número total de papeis x cotação + divida liquida\n",
        "ev = market value +  liquid debt \n",
        "\n",
        "PSR = PREÇO DA AÇÃO / RECEITA LIQUIDA POR AÇÃO "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KMykScpd0dc"
      },
      "outputs": [],
      "source": [
        "# df_final = CALCULATE.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLHH-FBIgAzy"
      },
      "outputs": [],
      "source": [
        "# df_final.to_excel(\"/content/gdrive/MyDrive/Data/XLSX/Final/StocksFinal.xlsx\",\n",
        "#                   sheet_name=\"Stocks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MJkJf8SguRE"
      },
      "source": [
        "Pandas setting DataFrame to pandas format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-FFxq6uLe49F"
      },
      "outputs": [],
      "source": [
        "df_stat = Stat.toPandas()\n",
        "\n",
        "df_calc = CALCULATE.toPandas()\n",
        "\n",
        "df_rsc = RSCH.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BNc_zBG8j3zL"
      },
      "outputs": [],
      "source": [
        "df_stat.to_excel(r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\Final\\Stat.xlsx\",\n",
        "                 sheet_name=\"stat\")\n",
        "\n",
        "df_calc.to_excel(r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\Final\\Calcl.xlsx\",\n",
        "                 sheet_name=\"calc\")\n",
        "\n",
        "df_rsc.to_excel(r\"C:\\Users\\video\\Desktop\\Projetos\\API\\F-A_root_project\\Final\\RSCH.xlsx\",\n",
        "                sheet_name=\"research\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "598092329803f2218a82426b846daf764474eee9678032408d5a767cd4823601"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
