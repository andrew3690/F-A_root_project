{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andrew3690/F-A_root_project/blob/Brazil/C%C3%B3pia_de_Research_Stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4JRZip-LxGM"
   },
   "source": [
    "# Downloading Modules:\n",
    "Spark, pyspark, Java.\n",
    "\n",
    "Bellow it is the old fashion way, risky not Recomended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "g7uf9T1SAwMe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# # Installing Java\\n! apt-get install openjdk-8-jdk-headless -qq > /dev/null\\n# # Dowload Spark\\n! wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\\n# # Decompressing archives\\n! tar xf spark-3.2.1-bin-hadoop2.7.tgz\\n# # installing findspark\\n! pip install -q findspark\\n# # installing pyspark\\n! pip install pyspark==3.2.1\\n '"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "# # Installing Java\n",
    "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# # Dowload Spark\n",
    "! wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
    "# # Decompressing archives\n",
    "! tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
    "# # installing findspark\n",
    "! pip install -q findspark\n",
    "# # installing pyspark\n",
    "! pip install pyspark==3.2.1\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "V3ZS9Z2vYrxT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Importing os library\\nimport os\\n# # Java envirorment variable\\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\\n# # Spark envirorment variable\\nos.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\\n '"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "# Importing os library\n",
    "import os\n",
    "# # Java envirorment variable\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# # Spark envirorment variable\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTYBnobCPITD"
   },
   "source": [
    "# Better and consistent library that makes the same function as the code above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boHa2yWHE2TA",
    "outputId": "2dd293d0-7923-4351-a6b7-66b27aea85f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/andre/.local/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j in /home/andre/.local/lib/python3.10/site-packages (0.10.9.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyodbc in /home/andre/.local/lib/python3.10/site-packages (4.0.35)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m432.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/17.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m:10\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/base_command.py\", line 165, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/req_command.py\", line 205, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/commands/install.py\", line 339, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 373, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 204, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 215, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 288, in __init__\n",
      "    super().__init__(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 299, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 487, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 532, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 214, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/prepare.py\", line 94, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/network/download.py\", line 146, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/progress_bars.py\", line 304, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 512, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install pyspark py4j\n",
    "! pip install pyodbc\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0lpamJ2PhzT"
   },
   "source": [
    "**Importing modules and pandas library that will be used later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oLpozDIlCsnf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyodbc\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# import findspark\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# findspark.init()\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "# import findspark\n",
    "\n",
    "# findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "rLgNaJpJZWQf",
    "outputId": "375d6ea4-ab28-428e-9c70-d6742f2396f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-7VLQ9AP:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e9e5a80ad0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instatianting spark instance\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gooogle Colab Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70iuSZT29Tff",
    "outputId": "7fa9d57b-f0c2-4c24-d1d3-841ff740eb4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfrom google.colab import drive\\ndrive.mount('/content/gdrive', force_remount=True) \\n\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEDLrMlgMaTM"
   },
   "source": [
    "# Next cells acquire parquet data from remote files, and transpose it to spark format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "fille =r'C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/RAW_DATA/Parquet/Balance.parquet'\n",
    "\n",
    "balance = spark\\\n",
    "        .read.format(\"parquet\")\\\n",
    "        .option(\"inferSchema\", \"True\")\\\n",
    "        .option(\"header\",\"True\")\\\n",
    "        .parquet(fille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SubWtlFnNJHn"
   },
   "source": [
    "Creating Tables in order to manipulate data in SQL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "UD38ZEtovRHd"
   },
   "outputs": [],
   "source": [
    "# Balance table\n",
    "balance.createOrReplaceTempView(\"Balance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv8S8_6bCqBk"
   },
   "source": [
    "# Note 1: \n",
    "'DetToEquity' must be in percentage, try to get it done here or otherwise in Power Bi\n",
    "\n",
    "---\n",
    "\n",
    "# Note 2: \n",
    "Find a way to calculate Beta values from \n",
    "historical data get it from other sources, but try to calculate it localy (Talk with Felipe, about the period of time that will be used as 'ytd' or montlhy). \n",
    "\n",
    "# Fixed:\n",
    "Beta values could be acquired trough yahoo finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKpxqfnyBnmn"
   },
   "source": [
    "Listing brazilian companies that will be researched and getting hystorical financial data\n",
    "filters that our Analyst indicates: Raking companies by: EBIT/EV > 0, ROE > 0, **Daily equity < 1.000.000.000**, revenueGrowth > 0 AND Will be done apart :(5-year-history) and all margins must be postive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abGJeNp68atZ"
   },
   "source": [
    "Alternative operations, while dealing with a little amount of data, and it can be joined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance = spark.sql(\"\"\"\n",
    "SELECT  Ticker,\n",
    "        CAST(Data_de_Reporte as string),\n",
    "        Moeda,\n",
    "        CAST(Receita_a_Pagar as string),\n",
    "        CAST(Receitas_a_Receber as string),\n",
    "        CAST(Bens_de_Capital as string)\n",
    "FROM Balance\n",
    "WHERE Ticker NOT LIKE '%34.SA'\n",
    "AND Moeda = 'BRL'\n",
    "ORDER BY Ticker DESC;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----+---------------+------------------+---------------+\n",
      "|   Ticker|    Data_de_Reporte|Moeda|Receita_a_Pagar|Receitas_a_Receber|Bens_de_Capital|\n",
      "+---------+-------------------+-----+---------------+------------------+---------------+\n",
      "| ZAMP3.SA|2021-12-30 21:00:00|  BRL|      2.47917E8|         1.39267E8|     1.461068E9|\n",
      "| ZAMP3.SA|2020-12-30 21:00:00|  BRL|      2.17616E8|         1.05011E8|     1.461068E9|\n",
      "| ZAMP3.SA|2019-12-30 21:00:00|  BRL|      2.86432E8|          6.0361E7|      9.50768E8|\n",
      "| YDUQ3.SA|2019-12-30 21:00:00|  BRL|      1.26651E8|         7.59622E8|     1.139887E9|\n",
      "| YDUQ3.SA|2021-12-30 21:00:00|  BRL|      1.83529E8|         9.57746E8|     1.139887E9|\n",
      "| YDUQ3.SA|2020-12-30 21:00:00|  BRL|      2.51229E8|         8.90151E8|     1.139887E9|\n",
      "|XPBR31.SA|2019-12-30 21:00:00|  BRL|      2.66813E8|         4.58776E8|        23000.0|\n",
      "|XPBR31.SA|2022-12-30 21:00:00|  BRL|      6.17394E8|         4.87331E8|        24000.0|\n",
      "|XPBR31.SA|2021-12-30 21:00:00|  BRL|      8.67526E8|         4.19532E8|        23000.0|\n",
      "|XPBR31.SA|2020-12-30 21:00:00|  BRL|       8.5955E8|         4.55253E8|        23000.0|\n",
      "| WHRL4.SA|2021-12-30 21:00:00|  BRL|     4.191681E9|        2.842092E9|     1.159103E9|\n",
      "| WHRL4.SA|2019-12-30 21:00:00|  BRL|     2.472096E9|        1.352849E9|     1.159103E9|\n",
      "| WHRL4.SA|2020-12-30 21:00:00|  BRL|     3.349451E9|        2.190542E9|     1.159103E9|\n",
      "| WHRL3.SA|2020-12-30 21:00:00|  BRL|     3.349451E9|        2.190542E9|     1.159103E9|\n",
      "| WHRL3.SA|2019-12-30 21:00:00|  BRL|     2.472096E9|        1.352849E9|     1.159103E9|\n",
      "| WHRL3.SA|2021-12-30 21:00:00|  BRL|     4.191681E9|        2.842092E9|     1.159103E9|\n",
      "| WEST3.SA|2021-12-30 21:00:00|  BRL|       4.2907E7|          3.1836E7|      4.70891E8|\n",
      "| WEST3.SA|2019-12-30 21:00:00|  BRL|      8199000.0|         7745000.0|       3.9819E7|\n",
      "| WEST3.SA|2020-12-30 21:00:00|  BRL|       3.9583E7|         8872000.0|       4.0224E7|\n",
      "| VVEO3.SA|2021-12-30 21:00:00|  BRL|     1.293329E9|        1.183243E9|     1.771044E9|\n",
      "+---------+-------------------+-----+---------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Balance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGP5as1CK1uo"
   },
   "source": [
    "ev = número total de papeis x cotação + divida liquida\n",
    "ev = market value +  liquid debt \n",
    "\n",
    "PSR = PREÇO DA AÇÃO / RECEITA LIQUIDA POR AÇÃO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MJkJf8SguRE"
   },
   "source": [
    "Pandas setting DataFrame to pandas format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "-FFxq6uLe49F"
   },
   "outputs": [],
   "source": [
    "df_balance = Balance.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Data_de_Reporte</th>\n",
       "      <th>Moeda</th>\n",
       "      <th>Receita_a_Pagar</th>\n",
       "      <th>Receitas_a_Receber</th>\n",
       "      <th>Bens_de_Capital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZAMP3.SA</td>\n",
       "      <td>2019-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2.86432E8</td>\n",
       "      <td>6.0361E7</td>\n",
       "      <td>9.50768E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZAMP3.SA</td>\n",
       "      <td>2020-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2.17616E8</td>\n",
       "      <td>1.05011E8</td>\n",
       "      <td>1.461068E9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZAMP3.SA</td>\n",
       "      <td>2021-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2.47917E8</td>\n",
       "      <td>1.39267E8</td>\n",
       "      <td>1.461068E9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YDUQ3.SA</td>\n",
       "      <td>2019-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1.26651E8</td>\n",
       "      <td>7.59622E8</td>\n",
       "      <td>1.139887E9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YDUQ3.SA</td>\n",
       "      <td>2020-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2.51229E8</td>\n",
       "      <td>8.90151E8</td>\n",
       "      <td>1.139887E9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>AERI3.SA</td>\n",
       "      <td>2021-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>4.45286E8</td>\n",
       "      <td>1.26877E8</td>\n",
       "      <td>8.15102E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>AERI3.SA</td>\n",
       "      <td>2022-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>3.36048E8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.15102E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>AALR3.SA</td>\n",
       "      <td>2019-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>5.667E7</td>\n",
       "      <td>8.8789E7</td>\n",
       "      <td>6.12412E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>AALR3.SA</td>\n",
       "      <td>2020-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>9.4887E7</td>\n",
       "      <td>7.9679E7</td>\n",
       "      <td>6.12412E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>AALR3.SA</td>\n",
       "      <td>2021-12-30 21:00:00</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1.17548E8</td>\n",
       "      <td>1.04502E8</td>\n",
       "      <td>6.12412E8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ticker      Data_de_Reporte Moeda Receita_a_Pagar Receitas_a_Receber  \\\n",
       "0    ZAMP3.SA  2019-12-30 21:00:00   BRL       2.86432E8           6.0361E7   \n",
       "1    ZAMP3.SA  2020-12-30 21:00:00   BRL       2.17616E8          1.05011E8   \n",
       "2    ZAMP3.SA  2021-12-30 21:00:00   BRL       2.47917E8          1.39267E8   \n",
       "3    YDUQ3.SA  2019-12-30 21:00:00   BRL       1.26651E8          7.59622E8   \n",
       "4    YDUQ3.SA  2020-12-30 21:00:00   BRL       2.51229E8          8.90151E8   \n",
       "..        ...                  ...   ...             ...                ...   \n",
       "749  AERI3.SA  2021-12-30 21:00:00   BRL       4.45286E8          1.26877E8   \n",
       "750  AERI3.SA  2022-12-30 21:00:00   BRL       3.36048E8                0.0   \n",
       "751  AALR3.SA  2019-12-30 21:00:00   BRL         5.667E7           8.8789E7   \n",
       "752  AALR3.SA  2020-12-30 21:00:00   BRL        9.4887E7           7.9679E7   \n",
       "753  AALR3.SA  2021-12-30 21:00:00   BRL       1.17548E8          1.04502E8   \n",
       "\n",
       "    Bens_de_Capital  \n",
       "0         9.50768E8  \n",
       "1        1.461068E9  \n",
       "2        1.461068E9  \n",
       "3        1.139887E9  \n",
       "4        1.139887E9  \n",
       "..              ...  \n",
       "749       8.15102E8  \n",
       "750       8.15102E8  \n",
       "751       6.12412E8  \n",
       "752       6.12412E8  \n",
       "753       6.12412E8  \n",
       "\n",
       "[754 rows x 6 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel format tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "BNc_zBG8j3zL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ndf_stat.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Excel/Stat.xlsx\",\\n                 sheet_name=\"stat\")\\n\\ndf_calc.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Calcl.xlsx\",\\n                 sheet_name=\"calc\")\\n\\ndf_rsc.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/RSCH.xlsx\",\\n                sheet_name=\"research\")\\n\\ndf_balance.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Balance.xlsx\",\\n                sheet_name=\"balance\")\\n'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "df_stat.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Excel/Stat.xlsx\",\n",
    "                 sheet_name=\"stat\")\n",
    "\n",
    "df_calc.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Calcl.xlsx\",\n",
    "                 sheet_name=\"calc\")\n",
    "\n",
    "df_rsc.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/RSCH.xlsx\",\n",
    "                sheet_name=\"research\")\n",
    "\n",
    "df_balance.to_excel(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Balance.xlsx\",\n",
    "                sheet_name=\"balance\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parquet format table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "df_balance.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Balance.parquet\")\n",
    "\n",
    "df_stat.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Calcl.parquet\")\n",
    "\n",
    "df_rsc.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/RSCH.parquet\")\n",
    "\n",
    "df_calc.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Calcl.parquet\")\n",
    "\n",
    "\n",
    "df_balance.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Balance.parquet\")\n",
    "\n",
    "df_calendario.to_parquet(r\"C:/Users/video/Desktop/Projetos/API/F-A_root_project/notebooks/Final/Parquet/Calendario.parquet\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker                object\n",
      "Data_de_Reporte       object\n",
      "Moeda                 object\n",
      "Receita_a_Pagar       string\n",
      "Receitas_a_Receber    string\n",
      "Bens_de_Capital       string\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_balance['Bens_de_Capital'] = df_balance['Bens_de_Capital'].astype(\"string\")\n",
    "df_balance['Receitas_a_Receber'] = df_balance['Receitas_a_Receber'].astype(\"string\")\n",
    "df_balance['Receita_a_Pagar'] = df_balance['Receita_a_Pagar'].astype(\"string\")\n",
    "\n",
    "print(df_balance.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Connection to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DESKTOP-7VLQ9AP\\SQLEXPRESS;'\n",
    "                      'Database=FeA;'\n",
    "                      'Trusted_Connection=yes;'\n",
    "                      )\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Table insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ticker in enumerate(df_balance['Ticker']):\n",
    "    data = df_balance.loc[i,'Data_de_Reporte']\n",
    "\n",
    "    moeda = df_balance.loc[i,'Moeda']\n",
    "\n",
    "    receita = df_balance.loc[i,'Receita_a_Pagar']\n",
    "\n",
    "    receitas = df_balance.loc[i,'Receitas_a_Receber']\n",
    "\n",
    "    bens = df_balance.loc[i,'Bens_de_Capital']\n",
    "\n",
    "    dados = '\\'' + ticker + '\\'' + ',\\'' + data  + '\\'' + ',\\'' + moeda + '\\'' + ',\\'' + receita + '\\'' + ',\\'' + receitas + '\\'' + ',\\'' + bens + '\\''  ')'\n",
    "\n",
    "    script = '''INSERT INTO Balances ([Ticker],[Data_do_Reporte],[Moeda],[Receita_a_pagar],[Receitas_a_receber],[Bens_de_Capital]) VALUES ('''\n",
    "\n",
    "    query = script + dados\n",
    "\n",
    "    #print(query)\n",
    "\n",
    "    cursor.execute(query)\n",
    "\n",
    "    cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nserver_name = \"jdbc:sqlserver://DESKTOP-7VLQ9AP\\\\SQLEXPRESS\"\\ndatabase_name = \"FeA\"\\nurl = server_name + \";\" + \"databaseName=\" + database_name + \";\"\\n\\ntable_name = \"Balance\"\\nusername = \"SQL_ADM\"\\npassword = \"and010500\" # Please specify password here\\n\\ntry:\\n  df_balance.write     .format(\"com.microsoft.sqlserver.jdbc.spark\")     .mode(\"overwrite\")     .option(\"url\", url)     .option(\"dbtable\", table_name)     .option(\"user\", username)     .option(\"password\", password)     .save()\\n\\nexcept ValueError as error :\\n    print(\"Connector write failed\", error)\\n '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "server_name = \"jdbc:sqlserver://DESKTOP-7VLQ9AP\\SQLEXPRESS\"\n",
    "database_name = \"FeA\"\n",
    "url = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n",
    "\n",
    "table_name = \"Balance\"\n",
    "username = \"SQL_ADM\"\n",
    "password = \"and010500\" # Please specify password here\n",
    "\n",
    "try:\n",
    "  df_balance.write \\\n",
    "    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", table_name) \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .save()\n",
    "\n",
    "except ValueError as error :\n",
    "    print(\"Connector write failed\", error)\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "598092329803f2218a82426b846daf764474eee9678032408d5a767cd4823601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
